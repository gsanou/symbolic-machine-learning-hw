{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import HillClimbSearch, K2Score, BicScore\n",
    "from pgmpy.sampling.Sampling import BayesianModelSampling\n",
    "from pgmpy.factors.discrete.CPD import TabularCPD\n",
    "\n",
    "def JSD(P, Q):\n",
    "    # a divergence measure\n",
    "    _P = P / np.linalg.norm(P, ord=1)\n",
    "    _Q = Q / np.linalg.norm(Q, ord=1)\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    return 0.5 * (entropy(_P, _M) + entropy(_Q, _M))\n",
    "\n",
    "def total_variation_distance(P, Q):\n",
    "    _P = P / np.linalg.norm(P, ord=1)\n",
    "    _Q = Q / np.linalg.norm(Q, ord=1)\n",
    "    return np.abs(_P-_Q).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_csv('crash_sample_2018.csv', index_col=None)\n",
    "data.set_index('Unnamed: 0', inplace=True)\n",
    "\n",
    "nodes = list(data.columns)\n",
    "cat_to_num = {'AvgSpeed': {'low': 0, 'high': 1}, \\\n",
    "              'Country': {'US': 0, 'UK': 1, 'Europe': 2}, \\\n",
    "              'DangerLvl': {'low': 0, 'high': 1}, \\\n",
    "              'NoAccidents': {'low': 0, 'medium': 1, 'high': 2}, \\\n",
    "              'NoFatalities': {'low': 0, 'medium': 1, 'high': 2}, \\\n",
    "              'NoJourneys': {'low': 0, 'medium': 1, 'high': 2}, \\\n",
    "              'PoliceActivity': {'regular': 0, 'increased': 1}, \\\n",
    "              'RoadCond': {'bad': 0, 'good': 1}, \\\n",
    "              'Season': {'winter': 0, 'spring': 1, 'summer': 2, 'fall': 3}, \\\n",
    "              'Weather': {'bad': 0, 'good': 1}, \\\n",
    "              'Weekend': {'working': 0, 'weekend': 1, 'holiday': 2},\n",
    "              }\n",
    "\n",
    "num_to_cat = {}\n",
    "for k1, v1 in cat_to_num.items():\n",
    "    num_to_cat[k1] = {v2: k2 for k2, v2 in v1.items()}\n",
    "\n",
    "\n",
    "data.replace(cat_to_num, inplace=True)\n",
    "\n",
    "incomplete_mask = data.isnull().any(axis=1)\n",
    "incomplete_data = data[incomplete_mask].copy()\n",
    "complete_data = data[~incomplete_mask]\n",
    "\n",
    "training_mask = np.random.rand(len(complete_data)) < 0.8\n",
    "training_data = complete_data[training_mask]\n",
    "test_data = complete_data[~training_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    edges = [\n",
    "        (\"Season\", \"Weather\"),\n",
    "        (\"Weather\", \"RoadCond\"),\n",
    "        (\"RoadCond\", \"AvgSpeed\"),\n",
    "        (\"Country\", \"AvgSpeed\"),\n",
    "        (\"Weekend\", \"NoJourneys\"),\n",
    "        (\"NoJourneys\", \"AvgSpeed\"),\n",
    "        (\"PoliceActivity\", \"DangerLvl\"),\n",
    "        (\"RoadCond\", \"DangerLvl\"),\n",
    "        (\"AvgSpeed\", \"DangerLvl\"),\n",
    "        (\"DangerLvl\", \"NoAccidents\"),\n",
    "        (\"NoAccidents\", \"NoFatalities\"),\n",
    "    ]\n",
    "    model = BayesianModel(edges)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def check_independence(model, group1, group2, observed=[]):\n",
    "    for node1 in group1:\n",
    "        for node2 in group2:\n",
    "            if model.is_active_trail(node1, node2, observed):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "model = get_model()\n",
    "print(check_independence(model, [\"Season\"], [\"NoFatalities\"],[\"NoJourneys\"]))\n",
    "print(check_independence(model, [\"Weather\"], [\"NoAccidents\"],[\"RoadCond\"]))\n",
    "print(check_independence(model, [\"Season\"], [\"Weekend\"],[\"NoAccidents\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPT Learning (EM + MLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Completed\n",
      "Iteration 2: Completed\n",
      "Iteration 3: Completed\n",
      "Iteration 4: Completed\n",
      "Iteration 5: Completed\n",
      "Iteration 6: Completed\n",
      "Iteration 7: Completed\n",
      "Iteration 8: Completed\n",
      "Iteration 9: Completed\n",
      "Iteration 10: Completed\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "\"\"\"\n",
    "Warning: runs unsatisfactorily slow. \n",
    "\"\"\"\n",
    "\n",
    "def regenerate_incomplete_data(row, infer=None):\n",
    "    missing_column_mask = row.isnull()\n",
    "    incomplete_row = row[missing_column_mask]\n",
    "    complete_row = row[~missing_column_mask]\n",
    "    \n",
    "    missing_nodes = list(incomplete_row.to_dict().keys())\n",
    "    evidence = complete_row.astype(int).to_dict()\n",
    "\n",
    "    if len(missing_nodes) == 0:\n",
    "        return row\n",
    "    \n",
    "    prediction = infer.map_query(missing_nodes, evidence=evidence)\n",
    "    evidence.update(prediction)\n",
    "    return pd.Series(\n",
    "    )\n",
    "\n",
    "def e(incomplete_data, model):\n",
    "    infer = VariableElimination(model)\n",
    "    return incomplete_data.apply(regenerate_incomplete_data, axis=1, infer=infer)\n",
    "\n",
    "def m(training_data):\n",
    "    model = get_model()\n",
    "    mle = MaximumLikelihoodEstimator(model, training_data)\n",
    "    model.add_cpds(*mle.get_parameters())\n",
    "    return model\n",
    "\n",
    "model = m(training_data)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Iteration %d: \" % (i+1), end=\"\")\n",
    "    completed_data = e(incomplete_data, model)\n",
    "    model = m(pd.concat([training_data, completed_data]))\n",
    "    print(\"Completed\")\n",
    "    \n",
    "full_completed_data = pd.concat([complete_data, completed_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤═════════════════════╤═════════════════════╤═════════════════════╤════════════════════╤═════════════════════╤═════════════════════╤═════════════════════╤════════════════════╤═════════════════════╤════════════════════╤═════════════════════╤═════════════════════╕\n",
      "│ Country       │ Country(0.0)        │ Country(0.0)        │ Country(0.0)        │ Country(0.0)       │ Country(1.0)        │ Country(1.0)        │ Country(1.0)        │ Country(1.0)       │ Country(2.0)        │ Country(2.0)       │ Country(2.0)        │ Country(2.0)        │\n",
      "├───────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼─────────────────────┤\n",
      "│ NoJourneys    │ NoJourneys(0.0)     │ NoJourneys(0.0)     │ NoJourneys(1.0)     │ NoJourneys(1.0)    │ NoJourneys(0.0)     │ NoJourneys(0.0)     │ NoJourneys(1.0)     │ NoJourneys(1.0)    │ NoJourneys(0.0)     │ NoJourneys(0.0)    │ NoJourneys(1.0)     │ NoJourneys(1.0)     │\n",
      "├───────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼─────────────────────┤\n",
      "│ RoadCond      │ RoadCond(0.0)       │ RoadCond(1.0)       │ RoadCond(0.0)       │ RoadCond(1.0)      │ RoadCond(0.0)       │ RoadCond(1.0)       │ RoadCond(0.0)       │ RoadCond(1.0)      │ RoadCond(0.0)       │ RoadCond(1.0)      │ RoadCond(0.0)       │ RoadCond(1.0)       │\n",
      "├───────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼─────────────────────┤\n",
      "│ AvgSpeed(0.0) │ 0.762396694214876   │ 0.37943262411347517 │ 0.7677329624478443  │ 0.3818011257035647 │ 0.779874213836478   │ 0.34574468085106386 │ 0.7730061349693251  │ 0.3838383838383838 │ 0.7664864864864865  │ 0.3925619834710744 │ 0.7530959752321982  │ 0.38557343020238716 │\n",
      "├───────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼────────────────────┼─────────────────────┼─────────────────────┤\n",
      "│ AvgSpeed(1.0) │ 0.23760330578512398 │ 0.6205673758865248  │ 0.23226703755215578 │ 0.6181988742964353 │ 0.22012578616352202 │ 0.6542553191489362  │ 0.22699386503067484 │ 0.6161616161616161 │ 0.23351351351351352 │ 0.6074380165289256 │ 0.24690402476780185 │ 0.6144265697976129  │\n",
      "╘═══════════════╧═════════════════════╧═════════════════════╧═════════════════════╧════════════════════╧═════════════════════╧═════════════════════╧═════════════════════╧════════════════════╧═════════════════════╧════════════════════╧═════════════════════╧═════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(model.get_cpds(\"AvgSpeed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the long-awaited painfully-computed preciously-regenerated full completed data.\n",
    "full_completed_data.replace(num_to_cat).to_csv(\"full_completed_data.csv\")\n",
    "full_completed_data = pd.DataFrame.from_csv(\"full_completed_data.csv\").replace(cat_to_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8851.050358468436\n",
      "-8739.714029743163\n"
     ]
    }
   ],
   "source": [
    "scorer = K2Score(test_data)\n",
    "print(scorer.score(model))\n",
    "\n",
    "hc = HillClimbSearch(completed_data)\n",
    "best_model = hc.estimate()\n",
    "\n",
    "print(scorer.score(best_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DangerLvl', 'AvgSpeed'),\n",
       " ('DangerLvl', 'NoAccidents'),\n",
       " ('NoAccidents', 'NoFatalities'),\n",
       " ('NoJourneys', 'Weather'),\n",
       " ('NoJourneys', 'NoAccidents'),\n",
       " ('NoJourneys', 'Season'),\n",
       " ('PoliceActivity', 'AvgSpeed'),\n",
       " ('RoadCond', 'AvgSpeed'),\n",
       " ('RoadCond', 'DangerLvl'),\n",
       " ('Season', 'RoadCond'),\n",
       " ('Weather', 'RoadCond'),\n",
       " ('Weather', 'Season')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing the final model on the completed data\n",
    "edges = [\n",
    "    ('AvgSpeed', 'PoliceActivity'),\n",
    "    ('AvgSpeed', 'DangerLvl'),\n",
    "    ('DangerLvl', 'NoAccidents'),\n",
    "    ('DangerLvl', 'NoFatalities'),\n",
    "    ('NoAccidents', 'NoFatalities'),\n",
    "    ('Weather', 'NoJourneys'),\n",
    "    ('NoJourneys', 'NoAccidents'),\n",
    "    ('Season', 'NoJourneys'),\n",
    "    ('RoadCond', 'AvgSpeed'),\n",
    "    ('RoadCond', 'DangerLvl'),\n",
    "    ('Season', 'RoadCond'),\n",
    "    ('Weather', 'RoadCond'),\n",
    "    ('Season', 'Weather'),\n",
    "    ('Weekend', 'NoJourneys')\n",
    "]\n",
    "final_model = BayesianModel(edges)\n",
    "final_model.add_node(\"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(full_completed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.readwrite.BIF import BIFWriter\n",
    "writer = BIFWriter(final_model)\n",
    "writer.write_bif('najmami2.bif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jensen-Shannon Divergence and Total Variation Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "domain = tuple(list(d.values())for _, d in cat_to_num.items())\n",
    "combinations = list(product(*domain))\n",
    "full_combinations_index = pd.MultiIndex.from_tuples(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = BayesianModelSampling(final_model)\n",
    "model_samples = sampler.forward_sample(len(data))\n",
    "model_samples_frequencies = model_samples.groupby(nodes).size()\n",
    "model_samples_frequencies = model_samples_frequencies.reindex(full_combinations_index, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.108180479577\n",
      "0.00565511315316\n"
     ]
    }
   ],
   "source": [
    "full_completed_data_frequencies = full_completed_data.groupby(nodes).size().reindex(full_combinations_index, fill_value=0)\n",
    "print(JSD(model_samples_frequencies.values, full_completed_data_frequencies.values))\n",
    "print(total_variation_distance(model_samples_frequencies.values, full_completed_data_frequencies.values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
